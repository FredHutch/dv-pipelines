{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda3/lib/python3.8/site-packages/requests/__init__.py:89: RequestsDependencyWarning: urllib3 (1.26.4) or chardet (3.0.4) doesn't match a supported version!\n",
      "  warnings.warn(\"urllib3 ({}) or chardet ({}) doesn't match a supported \"\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import logging\n",
    "from operator import mul\n",
    "import time\n",
    "import os\n",
    "\n",
    "import pubweb.singlecell\n",
    "from pubweb.hdf5 import Hdf5\n",
    "from pubweb.commands.convert.singlecell.h5seurat import ImportH5Seurat\n",
    "from pubweb.commands.validate.dimensions import ValidateDimensions\n",
    "from pubweb.commands.annotate.geneid import AnnotateGeneId\n",
    "from pubweb.commands.annotate.geneset import AnnotateGeneset\n",
    "from pubweb.commands.export.lists import ExportLists\n",
    "from pubweb.commands.export.attributes import ExportAttributes\n",
    "from pubweb.commands.export.tables import ExportTables\n",
    "from pubweb.commands.export.projections import ExportProjections\n",
    "from pubweb.commands.export.spatial import ExportSpatial\n",
    "from pubweb.commands.export.matrices import ExportMatrices\n",
    "#from pubweb.commands.export.matrix_sparse import ExportMatrixSparse\n",
    "#from pubweb.commands.export.matrix_dense import ExportMatrixDense\n",
    "from pubweb.commands.summarize.genes import SummarizeGenes\n",
    "from pubweb.commands.summarize.genemap import SummarizeGeneMap\n",
    "from pubweb.commands.summarize.colors import SummarizeColors\n",
    "from pubweb.commands.summarize.manifest import SummerizeManifest\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import os\n",
    "import h5py\n",
    "from h5py import Dataset, Group, File\n",
    "import pandas\n",
    "import numpy as np\n",
    "import boto3\n",
    "import re\n",
    "from io import BytesIO\n",
    "from urllib.parse import urlparse\n",
    "from shutil import copyfile\n",
    "from pathlib import Path\n",
    "from pubweb.enums import Attribute\n",
    "from pubweb.hdf5 import Hdf5\n",
    "from pubweb.commands.command import Command\n",
    "import logging\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(level='DEBUG')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasetName='lee-diffexp'\n",
    "fileToConvert = '/data/notebooks/input/lee_2020_processed.h5seurat'\n",
    "outputFolder = '/data/notebooks/pubweb'\n",
    "species = 'human'\n",
    "overwriteHdf5 = True\n",
    "python_wd = '/opt/pubweb'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = h5py.File(fileToConvert, \"r\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# h5seurat\n",
    "outputFile = f'{outputFolder}/pubweb.hdf5'\n",
    "if os.path.exists(outputFile) and overwriteHdf5:\n",
    "    os.remove(outputFile)\n",
    "hdf5 = Hdf5.load(outputFile, \"a\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<HDF5 dataset \"levels\": shape (28,), type \"|O\">"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['active.ident/levels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%time hdf5 | ImportH5Seurat(fileToConvert, datasetName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hdf5.h5py['pubweb/lee-diffexp'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<HDF5 dataset \"cell.names\": shape (71509,), type \"|O\">"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['cell.names']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "src = Hdf5.load(fileToConvert, \"r\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# H5seurat.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = f'/pubweb/{datasetName}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "pconf = {\n",
    "    \"cell\": \"cell.names\",\n",
    "    \"reductions/pca/cell.embeddings\": {\"type\": \"projection\",\n",
    "                                       \"col\": \"reductions/pca/features\"\n",
    "                                      },\n",
    "    \"reductions/pca/features\": {\"gene\": 1},\n",
    "    \"reductions/ref.spca/cell.embeddings\": {\"type\": \"projection\",\n",
    "                                            \"row\": \"cell.names\"},\n",
    "    \"reductions/ref.umap/cell.embeddings\": {\"type\": \"projection\",\n",
    "                                            \"row\": \"cell.names\"},\n",
    "    \"assays/RNA/counts\": {\"type\": \"matrix\"},\n",
    "    \"assays/RNA/data\": {\"type\": \"matrix\"},\n",
    "    \"assays/SCT/counts\": {\"type\": \"matrix\"},\n",
    "    \"assays/SCT/data\": {\"type\": \"matrix\"},\n",
    "    \"assays/predicted_ADT/data\": {\"type\": \"matrix\"},\n",
    "    \"assays/prediction.score.celltype.l1/data\": {\"type\": \"matrix\"},\n",
    "    \"assays/prediction.score.celltype.l2/data\": {\"type\": \"matrix\"},\n",
    "    \"assays/prediction.score.celltype.l3/data\": {\"type\": \"matrix\"},\n",
    "    \"misc/merged_umap\": {\"type\": \"matrix\"},\n",
    "    \"graphs/rna.snn\": {\"type\": \"matrix\"}\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "group = hdf5.h5py.create_group(f'{dataset}/lists')\n",
    "group = hdf5.h5py.create_group(f'{dataset}/tables')\n",
    "group = hdf5.h5py.create_group(f'{dataset}/matrix')\n",
    "group = hdf5.h5py.create_group(f'{dataset}/projections')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def copy_table(src, dest, table, dataset, rows_dataset=None, dest_prefix='tables', is_gene=False):\n",
    "    print(f'Copying table {table.name}')\n",
    "    dim_count = 1 if len (table.shape) == 1 else table.shape[1]\n",
    "    # figure out the names\n",
    "    name_bits = [ x for x in table.name.split('/') if len(x) > 0]\n",
    "    target_name = name_bits[-1].replace('.','_')\n",
    "    parent_name = \"_\".join(name_bits[:-1]).replace('.','_')\n",
    "    col_headers = np.array([f\"{os.path.basename(table.name)}-{n}\" for n in range(1, dim_count + 1)])\n",
    "    # make a new group and copy\n",
    "    target_path = f'{dataset}/{dest_prefix}/{parent_name}/{target_name}'\n",
    "    group = dest.h5py.create_group(target_path)\n",
    "    dest.h5py.create_dataset(f'{target_path}/columns', data=col_headers.astype(\"S10\"), dtype='S10')\n",
    "    src.h5py.copy(table.name, group, name=\"values\")\n",
    "    # add the rows dataset in some form\n",
    "    if rows_dataset is not None:\n",
    "        src.h5py.copy(rows_dataset, group, name=\"rows\")\n",
    "    else:\n",
    "        rowcount = len(table[:]) / len(col_headers)\n",
    "        print(f\"There are {rowcount} rows\")\n",
    "        row_headers = np.arange(rowcount)\n",
    "        dest.h5py.create_dataset(f'{target_path}/rows', data=row_headers.astype(\"S10\"), dtype='S10')\n",
    "    if is_gene:\n",
    "        print(f\"Setting PW:Gene for {target_path}/{table.name}\")\n",
    "        dest[f'{target_path}/{table.name}'].attrs.create(\"PW:Gene\", \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def copy_dense_matrix(src, dest, table_name, dataset):\n",
    "    # naming\n",
    "    name_bits = [ x for x in table_name.split('/') if len(x) > 0]\n",
    "    target_name = name_bits[-1].replace('.','_')\n",
    "    parent_name = \"_\".join(name_bits[:-1]).replace('.','_')\n",
    "    print(f\"Copying dense matrix from {table_name} to /matrix/{parent_name}\")\n",
    "    # copy\n",
    "    # note, need to trim the leading '/' off to use getGroupsWithName\n",
    "    if len(dest.getGroupsWithName(f\"{dataset}/matrix/{parent_name}\"[1:])) < 1:\n",
    "        group = dest.h5py.create_group(f'{dataset}/matrix/{parent_name}')\n",
    "    src.h5py.copy(table_name, dest[f\"{dataset}/matrix/{parent_name}\"])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def copy_sparse_matrix(src, dest, group_name, dataset):\n",
    "    print(f'Copying sparse matrix from {group_name}')\n",
    "    target_name = group_name.replace('/','_')\n",
    "    # make a new group and copy\n",
    "    group = dest.h5py.create_group(f'{dataset}/matrix/{target_name}')\n",
    "    src.h5py.copy(f\"{group_name}/data\", group)\n",
    "    src.h5py.copy(f\"{group_name}/indices\", group)\n",
    "    src.h5py.copy(f\"{group_name}/indptr\", group)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def copy_projection(src, dest, table_name, dataset, rows_dataset=None, cols_dataset=None):\n",
    "    # naming and headers\n",
    "    projection_name = table_name.replace('ref.', '').replace('.','_').replace('/','.')\n",
    "    dim_count = src[table_name].shape[0]\n",
    "    target_path = f'{dataset}/projections/{projection_name}/{dim_count}'\n",
    "    if cols_dataset is None:\n",
    "        cols_dataset = np.array([f\"{os.path.basename(table_name)}-{n}\" for n in range(1, dim_count + 1)])\n",
    "    # now copy everything\n",
    "    group = dest.h5py.create_group(target_path)\n",
    "    dest.h5py.create_dataset(f'{target_path}/columns', data=cols_dataset.astype(\"S10\"), dtype='S10')\n",
    "    src.h5py.copy(f'{table_name}', group, name=\"values\")\n",
    "    if rows_dataset is not None:\n",
    "        src.h5py.copy(rows_dataset, group, name=\"rows\")\n",
    "    else:\n",
    "        rowcount = len(src[table_name][:]) / len(cols_dataset)\n",
    "        print(f\"There are {rowcount} rows\")\n",
    "        row_headers = np.arange(rowcount)\n",
    "        dest.h5py.create_dataset(f'{target_path}/rows', data=row_headers.astype(\"S10\"), dtype='S10')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def copy_group(src, dest, group_name, conf):\n",
    "    # get a list of datasets\n",
    "    group_conf = conf.get(group_name,{})\n",
    "    \n",
    "    current_datasets = src.getDatasetsWithPath(group_name)\n",
    "    current_dataset_bases = [x.replace(f\"{group_name}/\", '') for x in current_datasets]\n",
    "    \n",
    "    # sparse matrices are a special case\n",
    "    if group_conf.get('type') == 'matrix':\n",
    "        is_sparse = all(elem in current_dataset_bases for elem in [\"data\", \"indices\", \"indptr\"])\n",
    "        if is_sparse:\n",
    "            print(f'sparse copy from {group_name}/*')\n",
    "            copy_sparse_matrix(src, dest, group_name, dataset)\n",
    "    else:\n",
    "        for ds, ds_short in zip(current_datasets, current_dataset_bases):\n",
    "            # figure out what applies to this table\n",
    "            table_conf = conf.get(ds, {\"type\": \"table\"})\n",
    "            action = table_conf.get('type')\n",
    "            print(f\"Dataset '{ds}' has action={action}\")\n",
    "        # Do different copies depending on the action\n",
    "            if action == 'projection':\n",
    "                rows, cols = None, None\n",
    "                if table_conf.get('row') is not None:\n",
    "                    rows = src[table_conf.get('row')]\n",
    "                if table_conf.get('col') is not None:\n",
    "                    cols = src[table_conf.get('col')][:]\n",
    "                print(f\"copy_projection for {ds} has rows={rows} & cols={cols}\")\n",
    "                copy_projection(src=src,\n",
    "                                dest=dest,\n",
    "                                table_name=ds, \n",
    "                                dataset=dataset,\n",
    "                                rows_dataset=rows,\n",
    "                                cols_dataset=cols)   \n",
    "            elif action == 'matrix':\n",
    "                print(f\"copy matrix {ds}\")\n",
    "                copy_dense_matrix(src, dest, ds, dataset)\n",
    "            if action == 'table':\n",
    "                is_gene = True if table_conf.get('gene',0) == 1 else False\n",
    "                copy_table(src=src, dest=dest, table=src[ds], dataset=dataset, is_gene=is_gene)\n",
    "\n",
    "    # now recurse!\n",
    "    child_groups = src.getGroupsWithPath(group_name)\n",
    "    for child in child_groups:\n",
    "        #print(f\"Recursing down to {child}\")\n",
    "        copy_group(src, dest, child, conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:h5py._conv:Creating converter from 3 to 5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying top-level group active.ident\n",
      "Dataset 'active.ident/levels' has action=table\n",
      "Copying table /active.ident/levels\n",
      "There are 28.0 rows\n",
      "Dataset 'active.ident/values' has action=table\n",
      "Copying table /active.ident/values\n",
      "There are 71509.0 rows\n",
      "Copying top-level group assays\n",
      "Dataset 'assays/RNA/features' has action=table\n",
      "Copying table /assays/RNA/features\n",
      "There are 22221.0 rows\n",
      "sparse copy from assays/RNA/counts/*\n",
      "Copying sparse matrix from assays/RNA/counts\n",
      "sparse copy from assays/RNA/data/*\n",
      "Copying sparse matrix from assays/RNA/data\n",
      "Dataset 'assays/SCT/features' has action=table\n",
      "Copying table /assays/SCT/features\n",
      "There are 22160.0 rows\n",
      "Dataset 'assays/SCT/scale.data' has action=table\n",
      "Copying table /assays/SCT/scale.data\n"
     ]
    }
   ],
   "source": [
    "for k in src.h5py['/'].keys():\n",
    "    print(f\"Copying top-level group {k}\")\n",
    "    if isinstance(src[k], Dataset):\n",
    "        copy_table(src, dest=hdf5, table=src[k], dataset=dataset)\n",
    "    else:\n",
    "        copy_group(src=src, dest=hdf5, group_name=k, conf=pconf)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#src\n",
    "dest = hdf5\n",
    "group_name = 'reductions/ref.spca'\n",
    "conf = pconf\n",
    "\n",
    "# figure out what applies to this group\n",
    "current_conf = conf.get(group_name, {\"type\": \"table\"})\n",
    "print(f\"current conf {current_conf}\")\n",
    "\n",
    "action = current_conf.get('type')\n",
    "# get a list of datasets\n",
    "current_datasets = src.getDatasetsWithPath(group_name)\n",
    "current_dataset_bases = [x.replace(f\"{group_name}/\", '') for x in current_datasets]\n",
    "print(f\"current_datasets {current_datasets}\")\n",
    "\n",
    "\n",
    "if action == 'table':\n",
    "    for ds in current_datasets:\n",
    "        print(f\"copy table {ds}\")\n",
    "        copy_table(src, dest, src[ds], dataset)\n",
    "        \n",
    "    \n",
    "elif action == 'matrix':\n",
    "    is_sparse = all(elem in current_dataset_bases for elem in [\"data\", \"indices\", \"indptr\"])\n",
    "    if is_sparse:\n",
    "        print(f'sparse copy from {group_name}/*')\n",
    "        copy_sparse_matrix(src, dest, group_name, dataset)\n",
    "        #print(f\"Sparse matrix is {shape}\")\n",
    "    else:\n",
    "        for ds in current_datasets:\n",
    "            print(f\"copy matrix {ds}\")\n",
    "            copy_dense_matrix(src, dest, table_name, dataset)\n",
    "        \n",
    "elif action == 'projection':\n",
    "    print('projection')\n",
    "    # TODO ADD IN ,rows_dataset=?\n",
    "    copy_projection(src, dest, group_name, dataset)\n",
    "    \n",
    "else:\n",
    "    print(f\"Unknown type {action}, not sure how to copy\")\n",
    "\n",
    "\n",
    "# if it's a gene, add an attribute\n",
    "if current_conf.get('gene','') in current_datasets:\n",
    "    print(f\"gene dataset is {current_conf.get('gene')}\")\n",
    "\n",
    "# get a list of child groups\n",
    "child_groups = src.getGroupsWithPath(group_name)\n",
    "print(f\"child_groups {child_groups}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time hdf5 | AnnotateGeneId(species=species)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%time hdf5 | ExportProjections(outputFolder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time hdf5 | ExportTables(outputFolder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%time hdf5 | ExportMatrices(outputFolder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
